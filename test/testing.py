"""
This file is for code testing
"""


from gram2vec.verbalizer import Verbalizer
from gram2vec import vectorizer
from gram2vec.feature_locator import find_feature_spans
import numpy as np

config = {
    "pos_unigrams":1,
    "pos_bigrams":1,
    "func_words":1,
    "punctuation":1,
    "letters":1,
    "emojis":1,
    "dep_labels":1,
    "morph_tags":1,
    "sentences":1
    }

example_sentences = [
    "The quick brown ðŸ˜‚ fox jumps over the lazy dog.",
    "She sells seashells by the seashore.",
    "How much wood would a woodchuck chuck if a woodchuck could chuck wood?",
    "Peter Piper picked a peck of pickled peppers.",
    "A journey of a thousand miles begins with a single step.",
    "To be or not to be, that is the question.",
    "All that glitters is not gold.",
    "The early bird catches the worm.",
    "A picture is worth a thousand words.",
    "When in Rome, do as the Romans do."
]

# Extract features from example sentences
features = vectorizer.from_documents(example_sentences)
features.to_csv("features.csv", index=False)

# Find all occurrences of a specific feature in a text
# example_text = "The quick brown ðŸ˜‚ fox jumps over the lazy dog."
example_text = "<PERSON> passed away at <DATE_TIME> on <DATE_TIME>, in her home in <LOCATION>. <PERSON> was a doctor, who specialized in pediatric care."
print(f"\nAnalyzing text: \"{example_text}\"")

# Find all nouns
noun_spans = find_feature_spans(example_text, "pos_unigrams:NOUN")
print("\nNouns found:")
for span in noun_spans:
    print(f"  - '{span.text}' at positions {span.start_char}:{span.end_char}")

# Find all determiners
det_spans = find_feature_spans(example_text, "pos_unigrams:DET")
print("\nDeterminers found:")
for span in det_spans:
    print(f"  - '{span.text}' at positions {span.start_char}:{span.end_char}")

# Find all function words
the_spans = find_feature_spans(example_text, "func_words:the")
print("\nFunction word 'the' found:")
for span in the_spans:
    print(f"  - '{span.text}' at positions {span.start_char}:{span.end_char}")

# Find emojis
emoji_spans = find_feature_spans(example_text, "emojis:ðŸ˜‚")
print("\nEmojis found:")
for span in emoji_spans:
    print(f"  - '{span.text}' at positions {span.start_char}:{span.end_char}")

# Find punctuation
punct_spans = find_feature_spans(example_text, "punctuation:.")
print("\nPunctuation '.' found:")
for span in punct_spans:
    print(f"  - '{span.text}' at positions {span.start_char}:{span.end_char}")

# df = vectorizer.from_jsonlines("data/pan22/preprocessed/", config=config)
# test_vector = df.select_dtypes(include=np.number).iloc[111]

# verbalizer = Verbalizer(df)
# a = verbalizer.verbalize_author_id("en_112")

# d = verbalizer.verbalize_document_vector(test_vector)


# import ipdb;ipdb.set_trace()