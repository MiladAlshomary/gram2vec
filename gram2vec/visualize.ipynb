{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization notebook\n",
    "\n",
    "This notebook is meant for visualizing stuff and testing code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from nltk import Tree\n",
    "from spacy import displacy\n",
    "import spacy\n",
    "from more_itertools import chunked\n",
    "from dataclasses import dataclass\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "from featurizers import GrammarVectorizer, make_document\n",
    "from typing import List, Dict, Tuple, Set\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAN 2022 Summary Stats & Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Author:\n",
    "    \"\"\"\n",
    "    Stores author information in an easy to work with format\n",
    "    \n",
    "    :param author_id: unique author id\n",
    "    :param fixed_texts: list of author documents with regex fixes\n",
    "    :param raw_texts: list of author documents without regex fixes\n",
    "    :param discourse_types: list of discourse types\n",
    "    \n",
    "    Note: fixed_docs, raw_docs, and discourse_types are all 1 - 1 corresponding\n",
    "    \"\"\"\n",
    "    author_id:str\n",
    "    fixed_texts:list[str]\n",
    "    raw_texts:list[str]\n",
    "    discourse_types:list[str]\n",
    "    \n",
    "    def get_token_counts(self) -> list[int]:\n",
    "        return [len(word_tokenize(author_doc)) for author_doc in self.fixed_texts]\n",
    "    \n",
    "    def get_total_docs(self) -> int:\n",
    "        return len(self.fixed_texts)\n",
    "    \n",
    "    def count_dicourse_type(self, dtype:str) -> int:\n",
    "        return Counter(self.discourse_types)[dtype]\n",
    "        \n",
    "def load_json(path:str) -> dict[str, list[dict]]:\n",
    "    with open(path, \"r\") as fin:\n",
    "        data = json.load(fin)\n",
    "        return data\n",
    "\n",
    "def extract_from_dict(author_entry:dict, to_extract:str) -> list[str]:\n",
    "    return [entry[to_extract] for entry in author_entry]\n",
    "    \n",
    "def create_author_list(preprocessed_data:dict[str, list[dict]]) -> list[Author]:\n",
    "    \"\"\"\n",
    "    Converts the preprocessed data into a list of Author objects\n",
    "    \"\"\"\n",
    "    authors = []\n",
    "    for author_id in preprocessed_data.keys():\n",
    "        author_entry = preprocessed_data[author_id]\n",
    "        fixed_texts = extract_from_dict(author_entry,\"fixed_text\")\n",
    "        raw_texts = extract_from_dict(author_entry,\"raw_text\")\n",
    "        discourse_types = extract_from_dict(author_entry,\"discourse_type\")\n",
    "            \n",
    "        authors.append(Author(author_id, fixed_texts, raw_texts, discourse_types))\n",
    "        \n",
    "    return authors\n",
    "\n",
    "def get_doc_token_stats(authors:list[Author]) -> tuple[float, float]:\n",
    "    \"\"\"Gets the mean and std of tokens per document\"\"\"\n",
    "    all_doc_token_counts = []\n",
    "    for author in authors:\n",
    "        all_doc_token_counts.extend(author.get_token_counts())\n",
    "    return np.mean(all_doc_token_counts), np.std(all_doc_token_counts)\n",
    "    \n",
    "def make_author_df(authors:list[Author]) -> pd.DataFrame:\n",
    "    \n",
    "    author_maps = defaultdict(list)\n",
    "    for author in authors:\n",
    "        author_maps[\"author_id\"].append(author.author_id)\n",
    "        author_maps[\"total_token_count\"].append(sum(author.get_token_counts()))\n",
    "        author_maps[\"Total docs\"].append(author.get_total_docs())\n",
    "        author_maps[\"Emails\"].append(author.count_dicourse_type(\"email\"))\n",
    "        author_maps[\"Memos\"].append(author.count_dicourse_type(\"memo\"))\n",
    "        author_maps[\"Txt msgs\"].append(author.count_dicourse_type(\"text_message\"))\n",
    "        author_maps[\"Essays\"].append(author.count_dicourse_type(\"essay\"))\n",
    "        \n",
    "    return pd.DataFrame(author_maps)\n",
    "\n",
    "data = load_json(\"data/pan22/preprocessed/author_doc_mappings.json\")\n",
    "all_authors = create_author_list(data)\n",
    "df = make_author_df(all_authors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature testing ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2v = GrammarVectorizer()\n",
    "\n",
    "def get_all_documents(data_path:str, text_type=\"fixed_text\") -> list[str]:\n",
    "    \"\"\"Aggregates all documents into one list\"\"\"\n",
    "    all_documents = []\n",
    "    for author_entries in load_json(data_path).values():\n",
    "        for entry in author_entries:\n",
    "            all_documents.append(make_document(entry[text_type], g2v.nlp))\n",
    "            \n",
    "    return all_documents\n",
    "\n",
    "all_documents = get_all_documents(\"eval/pan22_splits/knn/train.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntactic construction featues?\n",
    "\n",
    "- Look for spacy tree pattern matcher online\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 are_AUX_ROOT                                   \n",
      "        ______________|_______________                           \n",
      "       |                       Apples_NOUN_nsub                 \n",
      "       |                              j                         \n",
      "       |                              |                          \n",
      "       |                       likes_VERB_relcl                 \n",
      "       |               _______________|________________          \n",
      "tasty_ADJ_acomp that_PRON_dobj                  John_PROPN_nsubj\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Apples that fall from trees taste good\"\n",
    "sentence = \"Apples that John likes are tasty\"\n",
    "nlp = g2v.nlp\n",
    "doc = nlp(sentence)\n",
    "\n",
    "def _to_nltk_tree(node):\n",
    "    \n",
    "    _tok_format = lambda tok: \"_\".join([tok.orth_, tok.pos_,tok.dep_])\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return Tree(_tok_format(node), [_to_nltk_tree(child) for child in node.children])\n",
    "    else:\n",
    "        return _tok_format(node)\n",
    "\n",
    "def get_nltk_tree(doc):\n",
    "    #https://stackoverflow.com/questions/36610179/how-to-get-the-dependency-tree-with-spacy\n",
    "    return [_to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]\n",
    "\n",
    "def get_root(doc) -> spacy.tokens.token.Token:\n",
    "    return [token for token in doc if token.head == token][0]\n",
    "\n",
    "def get_subject(root) -> spacy.tokens.token.Token:\n",
    "    return list(root.lefts)[0]\n",
    "\n",
    "\n",
    "# root = get_root(doc)\n",
    "# subject = get_subject(root)\n",
    "\n",
    "# for descendant in subject.subtree:\n",
    "\n",
    "#     print(descendant.text, descendant.dep_, descendant.n_lefts,\n",
    "#             descendant.n_rights,\n",
    "#             [ancestor.text for ancestor in descendant.ancestors])\n",
    "\n",
    "get_nltk_tree(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import DependencyMatcher\n",
    "from spacy.pipeline import merge_entities\n",
    "\n",
    "dobj_relcl = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary richness vector?\n",
    "\n",
    "- hapaxes\n",
    "- \\# of mispelled words?\n",
    "- "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.scripts.pan_create_bins import get_train_authors_sorted_by_docfreq\n",
    "\n",
    "def bin_authors(iterable) -> tuple[list[str], ...]:\n",
    "    return tuple(chunked(iterable, 7)) \n",
    "\n",
    "def make_doc_avg_labels(sorted_dict):\n",
    "       \n",
    "       labels = []\n",
    "       for bin in bin_authors(list(sorted_dict.values())):\n",
    "              labels.append(round(np.mean(bin), 2))\n",
    "       return labels\n",
    "\n",
    "train_path = \"eval/pan22_splits/knn/train.json\"\n",
    "train_authors_sorted = get_train_authors_sorted_by_docfreq(train_path)\n",
    "labels = make_doc_avg_labels(train_authors_sorted)\n",
    "\n",
    "# k = 6\n",
    "\n",
    "r_at_1 = np.array([0.02857142857,0.2285714286,0.1428571429,0.1428571429,0.2285714286,0.1142857143,0.2285714286,0.5142857143])\n",
    "\n",
    "r_at_8 = np.array([0.2571428571,0.5142857143,0.5142857143,0.5142857143,0.7142857143,0.6857142857,0.7142857143,0.7428571429,])\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "       \"Bin labels\": labels,\n",
    "       \"R@1\": r_at_1,\n",
    "       \"R@8\": r_at_8\n",
    "})\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "\n",
    "sns.lineplot(data=df, x=\"Bin labels\", y=\"R@1\",color=\"blue\",marker=\"o\", label=\"R@1\")\n",
    "sns.lineplot(data=df, x=\"Bin labels\", y=\"R@8\",color=\"green\",marker=\"o\", label=\"R@8\")\n",
    "plt.xlabel(\"Avg document count\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Binned author scores\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "df[\"Total docs\"].hist(bins=7)\n",
    "plt.title(\"Document counts per author\")\n",
    "plt.xlabel(\"# of documents\")\n",
    "plt.ylabel(\"# of authors\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains deprecated information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_FEATS_ACCS = [0.0, 0.05714285714285714, 0.11428571428571428, 0.17142857142857143, 0.2, 0.2, 0.2857142857142857, 0.5428571428571428]\n",
    "HALF_FEATS_ACCS = [0.0, 0.02857142857142857, 0.08571428571428572, 0.11428571428571428, 0.22857142857142856, 0.22857142857142856, 0.22857142857142856, 0.4]\n",
    "\n",
    "old_df = pd.DataFrame(\n",
    "    {\"Full features\": ALL_FEATS_ACCS,\n",
    "     \"Half features\": HALF_FEATS_ACCS,\n",
    "     \"Bin labels\":labels}\n",
    ")\n",
    "\n",
    "\n",
    "sns.lineplot(data=old_df, x=\"Bin labels\", y=\"Full features\",color=\"blue\", label=\"Full features\")\n",
    "sns.lineplot(data=old_df, x=\"Bin labels\", y=\"Half features\", color=\"red\", label=\"Half features\")\n",
    "plt.xlabel(\"Avg document count\")\n",
    "plt.ylabel(\"R@1 score\")\n",
    "plt.title(\"R@1 Development bin scores\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAN 2022 Discourse related stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_discourse_types(path:str) -> tuple[list,list,list]:\n",
    "    \"\"\"Loads the preprocessed data and sorts it by discourse type\"\"\"\n",
    "    preprocessed = load_json(path)\n",
    "    author_ids = preprocessed.keys()\n",
    "    emails = []\n",
    "    memos = []\n",
    "    txt_msgs = []\n",
    "    essays = []\n",
    "    for author_id in author_ids:\n",
    "        for author_entry in preprocessed[author_id]:\n",
    "            dtype = author_entry[\"discourse_type\"]\n",
    "            fixed = author_entry[\"fixed_text\"].split()\n",
    "            \n",
    "            if  dtype == \"email\":\n",
    "                emails.append(fixed)\n",
    "                \n",
    "            if  dtype == \"memo\":\n",
    "                memos.append(fixed)\n",
    "                \n",
    "            if  dtype == \"text_message\":\n",
    "                txt_msgs.append(fixed)\n",
    "                \n",
    "            if  dtype == \"essay\":\n",
    "                essays.append(fixed)\n",
    "    return emails, memos, txt_msgs, essays\n",
    "  \n",
    "def get_avg_tokens(dtype:list[list[str]]) -> int:\n",
    "    \n",
    "    token_counts = []\n",
    "    for tokens in dtype:\n",
    "        token_counts.append(len(tokens))\n",
    "    return np.mean(token_counts)\n",
    "              \n",
    "            \n",
    "emails, memos, txt_msgs, essays = load_all_discourse_types(\"data/pan22/preprocessed/preprocessed_data.json\")\n",
    "\n",
    "\n",
    "print(get_avg_tokens(emails))\n",
    "print(get_avg_tokens(memos))\n",
    "print(get_avg_tokens(txt_msgs))\n",
    "print(get_avg_tokens(essays))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "dtype_df = df[[\"Emails\", \"Txt msgs\", \"Essays\", \"Memos\"]].sum()\n",
    "dtype_df.plot.bar(color=[\"teal\", \"lightpink\", \"orange\", \"brown\"])\n",
    "plt.title(\"Discourse type counts\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blogs testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogs_preprocessed = pd.read_csv(\"data/blogs/preprocessed/blogs_preprocessed.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Token count threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "23166      1004.000000\n",
       "71075      1556.333333\n",
       "171591      711.114754\n",
       "207307      812.833333\n",
       "467705      800.689655\n",
       "              ...     \n",
       "4332599    1046.000000\n",
       "4333053     930.000000\n",
       "4333477     760.000000\n",
       "4334954     827.000000\n",
       "4337650    1175.000000\n",
       "Name: tkn_count, Length: 1370, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_TKN_CNT_THRESHOLD = 700\n",
    "\n",
    "author_avg_tkns = blogs_preprocessed.groupby(\"id\")[\"tkn_count\"].mean()\n",
    "\n",
    "author_avg_tkns[author_avg_tkns>AVG_TKN_CNT_THRESHOLD]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc count threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "8173       1007\n",
       "15365       844\n",
       "24336       849\n",
       "49663      1252\n",
       "78196       511\n",
       "           ... \n",
       "3522724    1052\n",
       "3523319    1052\n",
       "3585348    1060\n",
       "3667467     648\n",
       "3858248     619\n",
       "Name: id, Length: 148, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOC_CNT_THRESHOLD = 500\n",
    "\n",
    "author_doc_cnts= blogs_preprocessed.groupby(\"id\")[\"id\"].count()\n",
    "\n",
    "author_doc_cnts[author_doc_cnts>DOC_CNT_THRESHOLD]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining the thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tkn_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12530</th>\n",
       "      <td>1103084</td>\n",
       "      <td>Hey Class,   In case you'd like to have...</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12531</th>\n",
       "      <td>1103084</td>\n",
       "      <td>............................... setting...</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12532</th>\n",
       "      <td>1103084</td>\n",
       "      <td>...................................... ...</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12533</th>\n",
       "      <td>1103084</td>\n",
       "      <td>............................. comments ...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12534</th>\n",
       "      <td>1103084</td>\n",
       "      <td>discursive formations ....................</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id                                               text  tkn_count\n",
       "12530    1103084         Hey Class,   In case you'd like to have...        285\n",
       "12531    1103084         ............................... setting...        701\n",
       "12532    1103084         ...................................... ...        628\n",
       "12533    1103084         ............................. comments ...         47\n",
       "12534    1103084         discursive formations ....................        367"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def select_from_threshold(series:pd.Series, threshold:int) -> Set[int]:\n",
    "    \"\"\"Takes a pandas Series and selects indixes that meet a given threshold\"\"\"\n",
    "    return set(series[series > threshold].index.to_list())\n",
    "\n",
    "def extract_blog_authors(blogs_df:pd.DataFrame, avg_tok_threshold:int, doc_threshold:int) -> pd.DataFrame:\n",
    "    \"\"\"Selects authors from the blogs df that meet an avg token count threshold and doc frequency threshold\"\"\"\n",
    "    \n",
    "    author_avg_tkns = blogs_df.groupby(\"id\")[\"tkn_count\"].mean()\n",
    "    author_doc_cnts= blogs_df.groupby(\"id\")[\"id\"].count()\n",
    "\n",
    "    selected_avg_tkn_authors = select_from_threshold(author_avg_tkns, avg_tok_threshold)\n",
    "    selected_doc_cnt_authors = select_from_threshold(author_doc_cnts, doc_threshold)\n",
    "    selected_ids = selected_avg_tkn_authors.intersection(selected_doc_cnt_authors)\n",
    "    \n",
    "    return blogs_df.loc[blogs_df[\"id\"].isin(selected_ids)]\n",
    "\n",
    "    \n",
    "df_sample = extract_blog_authors(blogs_df = blogs_preprocessed, \n",
    "                                 avg_tok_threshold = 350, \n",
    "                                 doc_threshold = 200)\n",
    "df_sample = df_sample.rename(columns={\"id\":\"author_id\"})\n",
    "\n",
    "\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8426aeb6a0394c95a6dca738b4382d3e4f73a60ab3fca776cba99777e8eb1027"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
