{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization notebook\n",
    "\n",
    "\n",
    "\n",
    "## Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import spacy\n",
    "from spacy import Language\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "%matplotlib inline\n",
    "\n",
    "# 1,071,477 authors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring MUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ijson\n",
    "import sqlite3\n",
    "import random\n",
    "\n",
    "data = ijson.parse(open(\"data/mud/full/raw_mud/raw_all/data.jsonl\"),multiple_values=True)\n",
    "\n",
    "x = 0\n",
    "d = {}\n",
    "posts = []\n",
    "for prefix, event, value in data:\n",
    "    \n",
    "    if prefix == \"syms.item\":\n",
    "        posts.append(value)\n",
    "        \n",
    "    if prefix.startswith(\"author_id\"):\n",
    "        d[value] = posts\n",
    "        posts = []\n",
    "        x += 1\n",
    "\n",
    "    if x == 30:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "author = random.choice(list(d.keys()))\n",
    "\n",
    "\n",
    "save = {author:d[author]}\n",
    "print(len(d[author]))\n",
    "\n",
    "utils.save_json(save, \"example_author.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nlp \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mload_spacy(\u001b[39m\"\u001b[39m\u001b[39men_core_web_md\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mThis is a string and I eat ice cream!!!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m doc \u001b[39m=\u001b[39m nlp(text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "nlp = utils.load_spacy(\"en_core_web_md\")\n",
    "\n",
    "text = \"This is a string and I eat ice cream!!!\"\n",
    "doc = nlp(text)\n",
    "\n",
    "tokens = [token.text for token in doc]\n",
    "pos = [token.pos_ for token in doc]\n",
    "\n",
    "l = []\n",
    "for i, token in enumerate(tokens):\n",
    "    try:\n",
    "        l.append((token, pos[i+1]))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is a string and I eat ice cream."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = utils.load_spacy(\"en_core_web_md\")\n",
    "\n",
    "text = \"This is a string and I eat ice cream. g\"\n",
    "doc = nlp(text)\n",
    "\n",
    "arrays = []\n",
    "for token in doc:\n",
    "    arrays.append(token.vector)\n",
    "    \n",
    "d = np.mean(arrays, axis=0)\n",
    "\n",
    "\n",
    "list(doc.sents)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'a', 'string']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "string = \"This is is a string\".split()\n",
    "\n",
    "fdist = nltk.FreqDist(string)\n",
    "fdist.hapaxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39816ae5e1dd6efcfe0b7efe22b855e119119f64616b7b0086574424de20bb02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
